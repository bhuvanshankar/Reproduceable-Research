mean(test2, )
hw1_data = read.csv("hw1_data.csv")
y <- subset(hw1_data, Temp>90 & Ozone>31)
mean(y$Solar.R)
hw1_data = read.csv("hw1_data.csv")
#y <- subset(hw1_data, Temp>90 & Ozone>31)
#mean(y$Solar.R)
test2<-subset(airquality, Temp > 90 & !is.na(Ozone) & Ozone > 31, select = c(Solar.R))
mean(test2$Solar.R)
hw1_data = read.csv("hw1_data.csv")
test2<-subset(solarr, Temp > 90 & !is.na(Ozone) & Ozone > 31, select = c(Solar.R))
mean(test2$Solar.R)
hw1_data = read.csv("hw1_data.csv")
test2<-subset(airquality, Temp > 90 & !is.na(Ozone) & Ozone > 31, select = c(Solar.R))
mean(test2$Solar.R)
#Mean of Temp when month is 6
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month=6, select=c(Temp))
month
month <- subset(airquality, Month=6, select=c(Month, Temp))
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month=6, select=c(Month, Temp))
month
month <- subset(airquality, Month is.6, select=c(Month, Temp))
month <- subset(airquality, Month.is 6, select=c(Month, Temp))
month <- subset(airquality, Month==6, select=c(Month, Temp))
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==6, select=c(Month, Temp))
month
mean(month$Temp)
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5, select=c(Month, Temp))
month
max(month$Temp)
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5, select=c(Month, Temp))
max(month$Temp)
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5, select=c(Month, Temp))
max(month$Temp)
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5, select=c(Month, Temp))
max(month$Temp)
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5, select=c(Month, Ozone))
max(month$Ozone)
month
month <- subset(airquality, Month==5, select=c(Month, Ozone.!na))
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5 & Ozone!is.na(Ozone), select=c(Month, Ozone))
month
hw1_data = read.csv("hw1_data.csv")
month <- subset(airquality, Month==5 & !is.na(Ozone), select=c(Month, Ozone))
month
max(month)
swirl()
library(swirl)
swirl()
install_from_swirl("R Programming")
library(swirl)
swirl()
swirl()
swirl()
install_from_swirl("R Programming")
swirl()
install_course_zip("/Users/bhuvanshankar/Downloads/swirl_courses-master.zip", multi-TRUE, which_course="R Programming")
install_course_zip("/Users/bhuvanshankar/Downloads/swirl_courses-master.zip", multi=TRUE, which_course="R Programming")
swirl()
5+7
x<-5+7
x
y<-x-3
y
z<-c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt<-sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+1000
my_div
library("rPython", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?rPython
library(swirl)
ls()
rm(list=ls())
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersions("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cram, -time)
select(cran, -time)
select(cran, -5:20)
select(cran, X:size)
-5:20
(5:20)
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version=="3.1.1", country=="US")
?Comparison
filter(cran, r_version=<"3.0.2", country=="IN")
filter(cran, r_version<="3.0.2", country=="IN")
filter(cran, country == "US" | country =="IN")
filter(cran, size>100500, r_os=="linux-gnu")
filter(cran, r_version.is.na(c(3,5,NA,10)))
filter(cran, r_version=is.na(c(3,5,NA,10)))
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, r_verson.!is.na())
filter(cran, r_verson=!is.na())
filter(cran, !is.na(r_version))
cran2 <- select(cran, arrange())
cran2 <- select(cran, arrange(size:ip_id))
cran2 <- select(cran, arrange(c(size:ip_id))
f/
cran2 <- select(cran, arrange(size), arrange(ip_id))
cran2 <- select(cran, arrange(size, ip_id))
cran2 <- select(cran, arrange(size:ip_id))
cran2 <- select(cran, arrange())
cran2 <- select(cran, arrange(.size), arrange(.ip_id))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(ip_id, package, size)
cran3<-select(cran ip_id, package, size)
cran3<-select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb=size/2^20)
mutate(cran3, size_mb=size/2^20, size_gb=size_mb/2^10)
mutate(cran3, correct_size=size_gb+1000)
mutate(cran3, correct_size=size+1000)
summarize(cran, avg_bytes=mean(size))
swirl()
library(swirl)
Bhuvan
ls()
rm(list=ls())
quit()
unique(acs$AGEP)
source('~/.active-rstudio-document')
######## Question 1 ########
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "ClientID", "ClientSecret")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/rate_limit", config(token = github_token))
stop_for_status(req)
content(req)
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
######## Question 2 ########
library(sqldf)
acs <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "acs.csv")
acs <- read.csv("acs.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
######## Question 3 ########
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
fUrl <- "http://biostat.jhsph.edu/~jleek/contact.html"
fUrl <- url(fUrl)
htmlCode <- readLines(fUrl)
close(fUrl)
sapply(htmlCode[c(10, 20, 30, 100)], nchar)
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", data.for)
data <- read.csv("data.for", header=T)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", data.for)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
data <- read.csv("data.for", header=T)
head(data)
View(data)
dim(data)
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
dim(data)
head(data)
?read.fwf
dframe <- read.fwf("data")
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
#data <- read.csv("data.for", header=T)
dframe <- read.fwf("data")
data <- read.csv("data.for", header=T)
View(data)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
#data <- read.csv("data.for", header=T)
dframe <- read.fwf("data", widths = " ")
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
data <- read.csv("data.for", header=T)
df <- read.fwf(file=data,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
df <- read.fwf(file="data.for", widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
df
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
df <- read.fwf(file="data.for", header = TRUE, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
data <- read.csv("data.for", header=T)
df <- read.fwf(file="data.for", header = TRUE, widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
data <- download.file("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", "data.for")
data <- read.csv("data.for", header=T)
df <- read.fwf(file="data.for", widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
dim(df)
head(df)
head(data)
sum(df[, 4])
View(cran3)
install.packages("googlePublicData")
install.packages("googleVis")
library("googleVis", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
detach("package:googleVis", unload=TRUE)
library("googleVis", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("Rserve")
source('~/Documents/git/CleaningGettingData/BaltimoreCamera.R')
View(CameraData)
source('~/Documents/git/CleaningGettingData/BaltimoreData/BaltimoreCamera.R')
View(CameraData)
source('~/Documents/git/CleaningGettingData/BaltimoreData/BaltimoreCamera.R')
View(CameraData)
autoplot(CameraData$Location.1)
library("ggplot2")
autoplot(CameraData$Location.1)
library("Deducer", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?deducer
deducer()
detach("package:Deducer", unload=TRUE)
library("maps", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
us.cities("Baltimore")
library("maps")
maps.us.cities
usa
data(usaMapEnv)
swirl()
library(swirl)
swirl()
mydf<-read.csv(path2csv, stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <-tbl_df(mydf)
rm("mydf")
cran
quit()
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- group_by(cran, package)
by_package
summarise(by_package, mean(size))
summarize(by_package, mean(size))
submit()
submit()
count = n(),
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
head(top_counts, 20)
library(swirl)
swirl()
arrange(top_counts, count)
arrange(top_counts, desc(count))
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
?chain
submit()
submit()
submit()
print(chain2)
print(cran)
submit()
submit()
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id,
country,
package,
size) %>%
mutate(size_mb <- size/2^20)
print
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id,
country,
package,
size) %>%
mutate(size_mb <- size/2^20)
print
submit()
submit()
size_mb <- mutate(size/2^20)
submit()
reset()
summarize(cran)
View(top_unique)
View(top_countries)
View(result3)
submit()
submit()
# Use mutate() to add a column called size_mb that contains
# the size of each download in megabytes (i.e. size / 2^20).
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb <- size/2^20)
submit()
submit()
submit()
submit()
submit()
library(swirl)
swirl()
?select
quit()
library(swirl)
rm(list=ls())
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, grade, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
students2
res
?separate
separate(res, sex_class, c("sex", "class"))
submit
submit()
submit()
submit()
students3
View(students3)
?gather
submit()
?spread()
?spread
submit()
View(students3)
submit()
submit()
reset()
submit()
submit()
submit()
submit()
reset()
reset()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
gather(class, grade, class1:class5, na.rm = TRUE)
gather(students3, class, grade, class1:class5, na.rm = TRUE)
# This script builds on the previous one by appending
# a call to spread(), which will allow us to turn the
# values of the test column, midterm and final, into
# column headers (i.e. variables).
#
# You only need to specify two arguments to spread().
# Can you figure out what they are? (Hint: You don't
# have to specify the data argument since we're using
# the %>% operator.
#
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE) %>%
spread(test, c("midterm","final")) %>%
print
submit()
submit()
submit()
submit()
submit()
?extract_numeric
extract_numeric("class5")
?mutate
submit()
submit()
students4
?select
submit()
submit()
?uniquw
?unique
submit()
submit()
```{r, echo=FALSE}
---
title: "Untitled"
output: html_document
---
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.
When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
summary(cars)
```
You can also embed plots, for example:
```{r, echo=FALSE}
plot(cars)
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
install.packages(c("cluster", "KernSmooth", "mgcv"))
.10*.09
.10+.09
.12+.06-.17
(.12+.06-.17)*100
.17-.12-.06
(.12+.06)-.17
*100
.17-.12+.06
?qunif
qunif(.75, 0, 1 )
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
p <- c(.1, .2, .3, .4)
x <- 2 : 5
x
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
var(x)
var(Pr)
var(Prob)
var(temp)
mean(c(1,2,3,4))
?mean
?var
?pmf
var(x)
var(X)
install.packages("randomForest")
install.packages(c("cluster", "KernSmooth", "mgcv"))
install.packages("RCurl")
install.packages(c("cluster", "KernSmooth", "mgcv"))
install.packages("RCurl" method = curl)
install.packages(c("cluster", "KernSmooth", "mgcv"))
install.packages("randomForest")
install.packages(c("boot", "codetools", "foreign", "manipulate", "MASS", "Matrix", "mgcv", "nlme"))
install.packages(c("manipulate", "rmarkdown"))
setwd("~/Google Drive/WhalePath/Oil Prices & Jobs")
?download.file
install.packages("xlsx")
library("xlsx", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
# Load the libraries needed #
library("xlsx")
# Download the files #
oilPrices <- download.file("http://www.eia.gov/dnav/pet/hist_xls/RWTCm.xls", "oil.xls")
?xlsx
oilPrices <- read.xlsx("oil.xls")
load("~/Google Drive/WhalePath/Oil Prices & Jobs/oil.xls")
oilPrices <- read.xlsx("oil.xls",2)
View(oilPrices)
View(oilPrices)
oilPrices <- read.xlsx("oil.xls",2, startRow = 2)
View(oilPrices)
oilPrices <- read.xlsx("oil.xls",2, startRow = 3)
View(oilPrices)
str(oilPrices)
summary(oilPrices)
setwd("~/Dropbox/Academics/Reproduceable Research")
